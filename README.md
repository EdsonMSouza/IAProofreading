# Avaliador de Respostas com LLM

Este projeto tem como objetivo avaliar automaticamente respostas dissertativas utilizando um Modelo de Linguagem (LLM). Ele foi desenvolvido para processar uma planilha com respostas, gerar feedbacks e atribuir notas com base em critÃ©rios definidos, integrando-se a um endpoint local de LLM.

## ğŸ—‚ Estrutura do Projeto

```
app/
â”œâ”€â”€ avaliar.py                      # Script principal para executar a avaliaÃ§Ã£o via terminal
â”œâ”€â”€ core.py                         # FunÃ§Ãµes centrais de processamento e avaliaÃ§Ã£o
â”œâ”€â”€ llm.py                          # ComunicaÃ§Ã£o com o modelo de linguagem (LLM)
â”œâ”€â”€ gera_notas.ipynb               # Notebook para testes e geraÃ§Ã£o de notas
â””â”€â”€ data/
    â”œâ”€â”€ respostas_simuladas.xlsx               # Planilha de entrada com respostas
    â””â”€â”€ respostas_simuladas_avaliado.xlsx      # Resultado com notas e feedbacks
```

## ğŸš€ Como Executar

### 1. Requisitos

- Python 3.9+
- DependÃªncias do projeto (`requirements.txt`)
- Um servidor LLM local (como o LM Studio ou equivalente) escutando na URL configurada

### 2. ExecuÃ§Ã£o via linha de comando

Execute a avaliaÃ§Ã£o de uma planilha `.xlsx`:

```bash
python avaliar.py data/respostas_simuladas.xlsx
```

### 3. ExecuÃ§Ã£o via notebook

Abra o arquivo `gera_notas.ipynb` para testar ou visualizar o processo passo a passo.

## âš™ï¸ ConfiguraÃ§Ãµes

O modelo e a URL do endpoint sÃ£o configurÃ¡veis nos scripts, especialmente em `llm.py` e `avaliar.py`. Certifique-se de que o endpoint esteja acessÃ­vel e configurado corretamente.

## ğŸ§  Sobre o LLM

O projeto assume que um modelo de linguagem Ã© capaz de:

- Analisar perguntas e respostas
- Atribuir notas coerentes
- Gerar feedback textual personalizado

O modelo utilizado pode ser o `qwen2.5-7b-instruct-1m`, `gemma`, `mistral`, entre outros, desde que compatÃ­vel com o formato de requisiÃ§Ã£o da OpenAI API.

## ğŸ“‚ Dados

- `respostas_simuladas.xlsx`: Arquivo com colunas `EndereÃ§o de e-mail`, `Nome`, e perguntas com as respectivas respostas.
- `respostas_simuladas_avaliado.xlsx`: Resultado da avaliaÃ§Ã£o contendo feedback e nota para cada resposta.

## ğŸ“Œ ObservaÃ§Ãµes

- Este projeto Ã© de uso acadÃªmico e pode ser adaptado para diversas finalidades educacionais.
- Certifique-se de validar eticamente o uso de modelos de IA para avaliaÃ§Ãµes.

## Como citar este conteÃºdo

```
DE SOUZA, Edson Melo (2025, July 20). IAProofreading.
Available in: https://github.com/EdsonMSouza/IAProofreading
```

Or BibTeX for LaTeX:

```latex
@misc{desouza2020IAProofreading,
  author = {DE SOUZA, Edson Melo},
  title = {IAProofreading v.1.0},
  url = {https://github.com/EdsonMSouza/IAProofreading},
  year = {2025},
  month = {July},
  publisher = {GitHub}
}
```

## ğŸ“ LicenÃ§a

Esta obra estÃ¡ licenciada com uma LicenÃ§a [Creative Commons ShareAlike 4.0 Internacional](http://creativecommons.org/licenses/by-sa/4.0/).

[![CC BY-SA 4.0](https://licensebuttons.net/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)
